% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Deep Learning Notes},
  pdfauthor={Rafael Moret Galán},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{longtable,booktabs}
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\ifluatex
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{Deep Learning Notes}
\author{Rafael Moret Galán}
\date{}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{deep-learning-specialization}{%
\chapter{Deep Learning Specialization}\label{deep-learning-specialization}}

\begin{quote}
All the material in this book is obtained from the Specialization from DeepLearning.AI's course on Coursera.
\end{quote}

\begin{itemize}
\tightlist
\item
  Started: \textbf{14/03/2021}
\item
  Finished: \textbf{Working on it}
\end{itemize}

\hypertarget{deep-learning-basics}{%
\chapter{Deep Learning Basics}\label{deep-learning-basics}}

\hypertarget{whats-binary-classification}{%
\section{What's Binary Classification?}\label{whats-binary-classification}}

Binary Classification is a kind of problem in which we want to learn a classifier that can predict the output label from certain input features.
That label just has two possible values.

\hypertarget{logistic-regression}{%
\section{Logistic Regression}\label{logistic-regression}}

Is a learning algorithm suited for binary classification problems, where the output is a 0/1 label.

Given \(x \in \mathbb{R}^{n_x}\), want: \[\hat{y} = P(y = 1 | x)\]\\
\textbf{Parameters}: \(w \in \mathbb{R}^{n_x}, b \in \mathbb{R}\)\\
\textbf{Output}: \(\hat{y} = \sigma (w^Tx + b)\)

Where \(\sigma\) is the sigmoid function:

\includegraphics[width=0.5\textwidth,height=\textheight]{images/sigmoid.png}

\[\sigma (z) = \frac{1}{1 + e^{-z}}\]

\hypertarget{cost-function}{%
\subsection{Cost Function}\label{cost-function}}

Given \({(x^1, y^1), ..., (x^m, y^m)}\), we want \(\hat{y}^i \approx y^i\)

Now, we need a function to measure how well our algorithm is doing (\textbf{Loss/error function}). For example, we could use:

\begin{itemize}
\tightlist
\item
  \(\mathcal{L}(\hat{y},y) = \frac{1}{2}(\hat{y}-y)^2\)
\end{itemize}

The problem is that that function make our \textbf{optimization problem non-convex}, what means that will have multiple local optimum and our \textbf{Gradient Descent} algorithm may not find the global optimum.

The loss function that we want to really use is: \[\mathcal{L}(\hat{y},y) = -(y \log (\hat{y}) + (1-y) \log(1-\hat{y}))\]

But, we need to know how well is doing the algorithm (the selection of our parameters) in the entire training set, not just a single example. For that reason we need a \textbf{Cost function}:
\[J(w,b) = \frac{1}{m} \sum^{m}_{i=1} L(\hat{y}^{(i)},y^{(i)})= -\frac{1}{m} \sum^{m}_{i=1} y^{(i)}\log (y^{(i)}) + (1 - y^{(i)}) \log (1-\hat{y}^{(i)})\]

\begin{itemize}
\tightlist
\item
  \textbf{Loss function} (\(\mathcal{L}\)): Just applied to one single training example.
\item
  \textbf{Cost function} (\(J\)): Cost of our parameter. The average of the loss functions of the entire training set.
\end{itemize}

\hypertarget{gradient-descent}{%
\section{Gradient Descent}\label{gradient-descent}}

Now that we can measure how well our selection of the parameters is, the next logical step would be to determine those parameters trying to maximize how good they are, in other words, minimizing the error made.

Want to find \(w,b\) that minimize \(J(w,b)\).

\includegraphics[width=0.5\textwidth,height=\textheight]{images/convex.png}\\
\emph{Convex (one optimum) error function}

What \textbf{Gradient Descent} will do is start at an initial point (initialization) and iteratively take some steps in the steepest downhill direction updating the value of both parameters until it converges to the global optimum.

\begin{quote}
Repeat \{\\
 \(w := w - \alpha \frac{\partial J(w,b)}{\partial w}\)

 \(b := b - \alpha \frac{\partial J(w,b)}{\partial b}\)\\
\}
\end{quote}

Where \(\alpha\) is a parameter known as \textbf{\emph{Learning Rate}}.

\includegraphics[width=0.5\textwidth,height=\textheight]{images/exec_gradient.png}\\
\emph{Two possible execution of Gradient Descent (simplified)}

\hypertarget{remembering-the-chain-rule}{%
\subsection{Remembering the Chain Rule}\label{remembering-the-chain-rule}}

\begin{quote}
Using the \textbf{Chain Rule} we can decompose some derivatives in other simpler derivatives terms.
\end{quote}

Suppose:

\[
a = f(x), x = g(y), y = h(z)
\]
We can compute the derivative \(\frac{\partial a}{\partial z}\) like:
\[
\frac{\partial a}{\partial z} \stackrel{(Ch.rule)}{=} \\ 
\frac{\partial a}{\partial y} \frac{\partial y}{\partial z} \stackrel{(Ch.rule)}{=} \frac{\partial a}{\partial x} \frac{\partial x}{\partial y} \frac{\partial y}{\partial z} = \\ 
\frac{\partial f(x)}{\partial x} \frac{\partial g(y)}{\partial y} \frac{\partial h(z)}{\partial z}
\]

With the \textbf{Chain Rule} we can compute the product of all of those three derivatives above and calculate \(\frac{\partial a}{\partial z}\) easily.

\hypertarget{applying-gradient-descent-to-log.-regression}{%
\section{Applying Gradient Descent to Log. Regression}\label{applying-gradient-descent-to-log.-regression}}

In order to apply Gradient Descent we just need to compute the derivatives terms of the parameters of our model.

In other words, we just need to go backwards in the \emph{computation graph} to obtain the derivatives with respect to the first terms of the graph: the parameters of our model.

\hypertarget{one-example}{%
\subsection{One example of our training set}\label{one-example}}

\includegraphics[width=0.6\textwidth,height=\textheight]{images/graph_log_reg.png}\\
\emph{Computation graph for Logistic Regression}

\begin{itemize}
\tightlist
\item
  ``\(da\)'' \(= \frac{\partial \mathcal{L}(a,y)}{\partial a} = - \frac{y}{a} + \frac{1-y}{1-a}\)
\item
  ``\(dz\)'' \(= \frac{\partial \mathcal{L}(a,y)}{\partial z} = \frac{\partial \mathcal{L}}{\partial a} \frac{\partial a}{\partial z} = a - y\)
\item
  ``\(dwi\)'' \(= \frac{\partial \mathcal{L}(a,y)}{\partial w_i} = \frac{\partial \mathcal{L}}{\partial a} \frac{\partial a}{\partial z} \frac{\partial z}{\partial w_i} = x_i \frac{\partial \mathcal{L}}{\partial z}\)
\item
  ``\(db\)'' \(= \frac{\partial \mathcal{L}(a,y)}{\partial b} = \frac{\partial \mathcal{L}}{\partial a} \frac{\partial a}{\partial z} \frac{\partial z}{\partial b} = \frac{\partial \mathcal{L}}{\partial z}\)
\end{itemize}

Pay attention to that the derivatives terms that we want in order to apply \textbf{Gradient Descent} are \(\frac{\partial \mathcal{L}(a,y)}{\partial w_i}\) and \(\frac{\partial \mathcal{L}(a,y)}{\partial b}\)

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

* \textbf{Note}: \(\frac{\partial a}{\partial z}\) is the derivative of the sigmoid function (\(a(1-a)\))

\hypertarget{m-examples-of-our-training-set}{%
\subsection{m examples of our training set}\label{m-examples-of-our-training-set}}

\[
J(w,b) = \frac{1}{m} \sum^m_{i=1} \mathcal{L}(a^{(i)},y^{i})\\
a^{(i)} = \hat{y}^{(i)} = \sigma (z^{(i)}) = \sigma (w^Tx^{(i)} + b)
\]

As we can see, the \textbf{Cost function} is the average of the individual losses so we can intuit that the derivative with respect the parameters also is going to be the average, but this time of the derivatives of the individual loss terms.

\[
\frac{\partial}{\partial w_i}J(w,b) = \frac{1}{m} \sum^m_{i=1}\frac{\partial}{\partial w_i} \mathcal{L}(a^{(i)},y^{(i)})
\]

Being \(\frac{\partial}{\partial w_i}\mathcal{L}(a,y)\) the derivative term that we computed in the \protect\hyperlink{one-example}{previous example}.

\hypertarget{algorithm}{%
\subsubsection{Algorithm}\label{algorithm}}

\begin{quote}
\textbf{\(J=0\); \(dw_1=0\); \(dw_2=0\); \(db=0\)} \# \emph{accumulators}

\textbf{for \(i=1\) to \(m\) \{}\\
\textbf{  \(z^{(i)} = w^Tx^{(i)} + b\)}\\
\textbf{  \(a^{(i)} = \sigma (z^{(i)})\)}

\textbf{  \(J = J + -[y^{(i)}\log a^{(i)} + (1-y^{(i)})\log (1-a^{(i)})]\)}\\
\textbf{  \(dz^{(i)} = a^{(i)} - y^{(i)}\)}

\textbf{  \(dw_1 = dw_1 + x^{(i)}_1 dz^{(i)}\)}\\
\textbf{  \(dw_2 = dw_2 + x^{(i)}_2 dz^{(i)}\)}\\
\textbf{    \(\vdots\)}\\
\textbf{  \(db = db + dz^{(i)}\)}\\
\textbf{\}}

\textbf{\(J = J / m\)}\\
\textbf{\(dw_1 = dw_1 / m\)}\\
\textbf{\(dw_2 = dw_2 / m\)}\\
\textbf{\(db = db / m\)}
\end{quote}

Now, with all those calculations we can implement \textbf{one step} of the \textbf{Gradient Descent} algorithm.

\begin{quote}
\(w_1 := w_1 - \alpha \cdot dw_1\)\\
\(w_2 := w_2 - \alpha \cdot dw_2\)\\
  \(\vdots\)\\
\(b := b - \alpha \cdot db\)
\end{quote}

  \bibliography{book.bib,packages.bib}

\end{document}
